{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting social Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import backbone\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "from network_model import model\n",
    "from aux_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self):\n",
    "        detection_graph, self.category_index = backbone.set_model(\n",
    "            \"ssd_mobilenet_v1_coco_2018_01_28\", \"mscoco_label_map.pbtxt\"\n",
    "        )\n",
    "        self.sess = tf.InteractiveSession(graph=detection_graph)\n",
    "        self.image_tensor = detection_graph.get_tensor_by_name(\"image_tensor:0\")\n",
    "        self.detection_boxes = detection_graph.get_tensor_by_name(\"detection_boxes:0\")\n",
    "        self.detection_scores = detection_graph.get_tensor_by_name(\"detection_scores:0\")\n",
    "        self.detection_classes = detection_graph.get_tensor_by_name(\n",
    "            \"detection_classes:0\"\n",
    "        )\n",
    "        self.num_detections = detection_graph.get_tensor_by_name(\"num_detections:0\")\n",
    "        def get_category_index(self):\n",
    "            return self.category_index\n",
    "        def detect_pedestrians(self, frame):\n",
    "            input_frame = frame\n",
    "        image_np_expanded = np.expand_dims(input_frame, axis=0)\n",
    "        (boxes, scores, classes, num) = self.sess.run(\n",
    "            [\n",
    "                self.detection_boxes,\n",
    "                self.detection_scores,\n",
    "                self.detection_classes,\n",
    "                self.num_detections,\n",
    "            ],\n",
    "            feed_dict={self.image_tensor: image_np_expanded},\n",
    "        )\n",
    "        classes = np.squeeze(classes).astype(np.int32)\n",
    "        boxes = np.squeeze(boxes)\n",
    "        scores = np.squeeze(scores)\n",
    "        pedestrian_score_threshold = 0.35\n",
    "        pedestrian_boxes = []\n",
    "        total_pedestrians = 0\n",
    "        for i in range(int(num[0])):\n",
    "            if classes[i] in self.category_index.keys():\n",
    "                class_name = self.category_index[classes[i]][\"name\"]\n",
    "                # print(class_name)\n",
    "                if class_name == \"person\" and scores[i] > pedestrian_score_threshold:\n",
    "                    total_pedestrians += 1\n",
    "                    score_pedestrian = scores[i]\n",
    "                    pedestrian_boxes.append(boxes[i])\n",
    "\n",
    "        return pedestrian_boxes, total_pedestrians  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines_between_nodes(warped_points, bird_image, d_thresh):\n",
    "    p = np.array(warped_points)\n",
    "    dist_condensed = pdist(p)\n",
    "    dist = squareform(dist_condensed)\n",
    "    dd = np.where(dist < d_thresh * 6 / 10)\n",
    "    close_p = []\n",
    "    color_10 = (96,160,48)\n",
    "    lineThickness = 4\n",
    "    ten_feet_violations = len(np.where(dist_condensed < 10 / 6 * d_thresh)[0])\n",
    "    for i in range(int(np.ceil(len(dd[0]) / 2))):\n",
    "        if dd[0][i] != dd[1][i]:\n",
    "            point1 = dd[0][i]\n",
    "            point2 = dd[1][i]\n",
    "\n",
    "            close_p.append([point1, point2])\n",
    "\n",
    "            cv2.line(\n",
    "                bird_image,\n",
    "                (p[point1][0], p[point1][1]),\n",
    "                (p[point2][0], p[point2][1]),\n",
    "                color_10,\n",
    "                lineThickness,\n",
    "            )\n",
    "    dd = np.where(dist < d_thresh)\n",
    "    six_feet_violations = len(np.where(dist_condensed < d_thresh)[0])\n",
    "    total_pairs = len(dist_condensed)\n",
    "    danger_p = []\n",
    "    color_6 = (96,160,48)\n",
    "    for i in range(int(np.ceil(len(dd[0]) / 2))):\n",
    "        if dd[0][i] != dd[1][i]:\n",
    "            point1 = dd[0][i]\n",
    "            point2 = dd[1][i]\n",
    "\n",
    "            danger_p.append([point1, point2])\n",
    "            cv2.line(\n",
    "                bird_image,\n",
    "                (p[point1][0], p[point1][1]),\n",
    "                (p[point2][0], p[point2][1]),\n",
    "                color_6,\n",
    "                lineThickness,\n",
    "            )\n",
    "    # Display Birdeye view\n",
    "    cv2.imshow(\"Bird Eye View\", bird_image)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    return six_feet_violations, ten_feet_violations, total_pairs\n",
    "     \n",
    "    \n",
    "def plot_points_on_bird_eye_view(frame, pedestrian_boxes, M, scale_w, scale_h):\n",
    "    frame_h = frame.shape[0]\n",
    "    frame_w = frame.shape[1]\n",
    "    node_radius = 10\n",
    "    color_node = (96,160,48)  #96,160,48\n",
    "    thickness_node = 20\n",
    "    solid_back_color = (96,160,48) #41, 41, 41\n",
    "\n",
    "    blank_image = np.zeros(\n",
    "        (int(frame_h * scale_h), int(frame_w * scale_w), 3), np.uint8\n",
    "    )\n",
    "    blank_image[:] = solid_back_color\n",
    "    warped_pts = []\n",
    "    for i in range(len(pedestrian_boxes)):\n",
    "\n",
    "        mid_point_x = int(\n",
    "            (pedestrian_boxes[i][1] * frame_w + pedestrian_boxes[i][3] * frame_w) / 2\n",
    "        )\n",
    "        mid_point_y = int(\n",
    "            (pedestrian_boxes[i][0] * frame_h + pedestrian_boxes[i][2] * frame_h) / 2\n",
    "        )\n",
    "\n",
    "        pts = np.array([[[mid_point_x, mid_point_y]]], dtype=\"float32\")\n",
    "        warped_pt = cv2.perspectiveTransform(pts, M)[0][0]\n",
    "        warped_pt_scaled = [int(warped_pt[0] * scale_w), int(warped_pt[1] * scale_h)]\n",
    "\n",
    "        warped_pts.append(warped_pt_scaled)\n",
    "        bird_image = cv2.circle(\n",
    "            blank_image,\n",
    "            (warped_pt_scaled[0], warped_pt_scaled[1]),\n",
    "            node_radius,\n",
    "            color_node,\n",
    "            thickness_node,\n",
    "        )\n",
    "\n",
    "    return warped_pts, bird_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_perspective(img, src_points):\n",
    "    IMAGE_H = img.shape[0]\n",
    "    IMAGE_W = img.shape[1]\n",
    "    src = np.float32(np.array(src_points))\n",
    "    dst = np.float32([[0, IMAGE_H], [IMAGE_W, IMAGE_H], [0, 0], [IMAGE_W, 0]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    return M, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text(frame, text, text_offset_y=25):\n",
    "    font_scale = 0.8\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    rectangle_bgr = (35, 35, 35)\n",
    "    (text_width, text_height) = cv2.getTextSize(\n",
    "        text, font, fontScale=font_scale, thickness=1\n",
    "    )[0]\n",
    "    # set the text start position\n",
    "    text_offset_x = frame.shape[1] - 400\n",
    "    # make the coords of the box with a small padding of two pixels\n",
    "    box_coords = (\n",
    "        (text_offset_x, text_offset_y + 5),\n",
    "        (text_offset_x + text_width + 2, text_offset_y - text_height - 2),\n",
    "    )\n",
    "    frame = cv2.rectangle(\n",
    "        frame, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED\n",
    "    )\n",
    "    frame = cv2.putText(\n",
    "        frame,\n",
    "        text,\n",
    "        (text_offset_x, text_offset_y),\n",
    "        font,\n",
    "        fontScale=font_scale,\n",
    "        color=(96,160,48), #255, 255, 255\n",
    "        thickness=1,\n",
    "    )\n",
    "\n",
    "    return frame, 2 * text_height + text_offset_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stay_at_home_index(total_pedestrians_detected, frame_num, fps):\n",
    "    normally_people = 10\n",
    "    pedestrian_per_sec = np.round(total_pedestrians_detected / frame_num, 1)\n",
    "    sh_index = 1 - pedestrian_per_sec / normally_people\n",
    "    return pedestrian_per_sec, sh_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pedestrian_boxes_on_image(frame, pedestrian_boxes):\n",
    "    frame_h = frame.shape[0]\n",
    "    frame_w = frame.shape[1]\n",
    "    thickness = 2\n",
    "    # color_node = (80, 172, 110)\n",
    "    color_node = (96,160,48)\n",
    "    # color_10 = (160, 48, 112)\n",
    "\n",
    "    for i in range(len(pedestrian_boxes)):\n",
    "        pt1 = (\n",
    "            int(pedestrian_boxes[i][1] * frame_w),\n",
    "            int(pedestrian_boxes[i][0] * frame_h),\n",
    "        )\n",
    "        pt2 = (\n",
    "            int(pedestrian_boxes[i][3] * frame_w),\n",
    "            int(pedestrian_boxes[i][2] * frame_h),\n",
    "        )\n",
    "\n",
    "        frame_with_boxes = cv2.rectangle(frame, pt1, pt2, color_node, thickness)\n",
    "\n",
    "\n",
    "    return frame_with_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
